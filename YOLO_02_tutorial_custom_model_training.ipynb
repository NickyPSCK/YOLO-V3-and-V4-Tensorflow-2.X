{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Custom Training YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from yolo.tools import XMLtoInputConvertor\n",
    "from yolo.data import YOLODatasetGenerator\n",
    "from yolo.estimator import YOLOEstimator\n",
    "from yolo.detector import YOLOObjectDetector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert XML anotations to YOLO input format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IC = XMLtoInputConvertor()\n",
    "\n",
    "IC.convert(XML_dir='example_trainset/apple.v1-apple-dataset.voc/train', \n",
    "           annotation_path='example_trainset/apple.v1-apple-dataset.voc/processed_anotation/train.txt')\n",
    "\n",
    "IC.convert(XML_dir='example_trainset/apple.v1-apple-dataset.voc/valid', \n",
    "           annotation_path='example_trainset/apple.v1-apple-dataset.voc/processed_anotation/valid.txt')\n",
    "\n",
    "IC.export_class_names(class_names_path='example_trainset/apple.v1-apple-dataset.voc/processed_anotation/class.txt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v4_tiny'\n",
    "\n",
    "train_data = YOLODatasetGenerator(anotation_path='example_trainset/apple.v1-apple-dataset.voc/processed_anotation/train.txt',\n",
    "                                  version=version,\n",
    "                                  input_sizes=416,\n",
    "                                  batch_size=4,\n",
    "                                  data_aug=False,\n",
    "                                  load_images_to_ram=True,\n",
    "                                  anchor_per_scale=3,\n",
    "                                  max_bbox_per_scale=100)\n",
    "\n",
    "valid_data = YOLODatasetGenerator(anotation_path='example_trainset/apple.v1-apple-dataset.voc/processed_anotation/valid.txt',\n",
    "                                 version=version,\n",
    "                                 input_sizes=416,\n",
    "                                 batch_size=3,\n",
    "                                 data_aug=False,\n",
    "                                 load_images_to_ram=True,\n",
    "                                 anchor_per_scale=3,\n",
    "                                 max_bbox_per_scale=100)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_custom_estimator = YOLOEstimator(version=version, \n",
    "                                      input_size=416, \n",
    "                                      channels=3, \n",
    "                                      inference_using_pretrained=False, \n",
    "                                      init_pretrained_weight=True, \n",
    "                                      disable_gpu=False,\n",
    "                                      pretrained_weight_dir='./pretrained_weight/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_custom_estimator.fit(train_data=train_data,\n",
    "                          val_data=valid_data,\n",
    "                          epocs=20,\n",
    "                          warmup_epocs=5,\n",
    "                          save_checkpoint=False,\n",
    "                          save_best_only=True)\n",
    "yolo_custom_estimator.save(model_dir='custom_model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_custom_detector = YOLOObjectDetector(model=yolo_custom_estimator, \n",
    "                                          classes=['apple'])\n",
    "\n",
    "image_path = 'example_trainset/apple.v1-apple-dataset.voc/valid/AnyConv-com__38_jpg.rf.efc76c3d7c82233abb99ad2c7bcc2f05.jpg'\n",
    "image_rgb = cv2.imread(image_path)\n",
    "image_rgb = cv2.cvtColor(image_rgb, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "result, bboxes = yolo_custom_detector.detect_image(image_rgb=image_rgb, \n",
    "                                                   score_threshold=0.5, \n",
    "                                                   iou_threshold=0.5,\n",
    "                                                   show_label=True,\n",
    "                                                   show_confidence=True)\n",
    "plt.imshow(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b3dcba9d1769d91a89d106acc0090f040dd1f5adaa19f85efba87bd460e37cfc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
